{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI/ML methods notebook\n",
        "\n"
      ],
      "metadata": {
        "id": "QG3X-tGIpkMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install Python packages\n",
        "This notebook is equipped with a dedicated login shell, tailored to the environment in which it is executed. If you are utilizing your personal compute system, such as a laptop, the login corresponds to your individual compute system login. Conversely, when running this notebook on Google Colab, the login is attributed to the root user. The initiation of Linux shell commands within Jupyter notebook code cells is denoted by a preceding exclamation point (!).\n",
        "\n",
        "In the code cell below, the provided pip commands are employed to install a range of Python libraries essential for the tasks covered in this notebook. It's worth noting that additional Python libraries are automatically installed within our virtual environment."
      ],
      "metadata": {
        "id": "gMEmAFI5sAuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XPbm2EcyIs_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn --no-cache\n",
        "!pip install scanpy --no-cache\n",
        "!pip install gseapy --no-cache\n",
        "!pip install pybiomart==0.1 --no-cache\n",
        "#!pip install mygene --no-cache\n",
        "!pip install sklearn_som  --no-cache\n",
        "!pip install pandas --no-cache\n",
        "!pip install numpy --no-cache\n",
        "!pip install matplotlib --no-cache\n",
        "!pip install sklearn-som --no-cache\n",
        "!pip install pyDeseq2 --no-cache\n",
        "!pip install Ensembl_converter --no-cache\n",
        "!pip install shap"
      ],
      "metadata": {
        "id": "bb8-MziuOeFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa1bb77-0ca7-4241-f803-7bd9621b0768",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting scanpy\n",
            "  Downloading scanpy-1.11.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting anndata>=0.8 (from scanpy)\n",
            "  Downloading anndata-0.11.4-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: h5py>=3.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.13.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.4.2)\n",
            "Collecting legacy-api-wrap>=1.4 (from scanpy)\n",
            "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.10.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.4.2)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scanpy) (2.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scanpy) (24.2)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (2.2.2)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.5.13)\n",
            "Collecting scikit-learn<1.6.0,>=1.1 (from scanpy)\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.14.1)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.13.2)\n",
            "Collecting session-info2 (from scanpy)\n",
            "  Downloading session_info2-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from scanpy) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from scanpy) (4.13.1)\n",
            "Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.5.7)\n",
            "Collecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n",
            "  Downloading array_api_compat-1.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->scanpy) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->scanpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->scanpy) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.1->scanpy) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->scanpy) (1.17.0)\n",
            "Downloading scanpy-1.11.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anndata-0.11.4-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
            "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m153.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading session_info2-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading array_api_compat-1.11.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: session-info2, legacy-api-wrap, array-api-compat, scikit-learn, anndata, scanpy\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed anndata-0.11.4 array-api-compat-1.11.2 legacy-api-wrap-1.4.1 scanpy-1.11.1 scikit-learn-1.5.2 session-info2-0.1.2\n",
            "Collecting gseapy\n",
            "  Downloading gseapy-1.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from gseapy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gseapy) (1.14.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gseapy) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.11/dist-packages (from gseapy) (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gseapy) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gseapy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gseapy) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gseapy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gseapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gseapy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gseapy) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2->gseapy) (1.17.0)\n",
            "Downloading gseapy-1.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.8/590.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gseapy\n",
            "Successfully installed gseapy-1.1.8\n",
            "Collecting pybiomart==0.1\n",
            "  Downloading pybiomart-0.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pybiomart==0.1) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pybiomart==0.1) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pybiomart==0.1) (2.32.3)\n",
            "Collecting requests_cache (from pybiomart==0.1)\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pybiomart==0.1) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pybiomart==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pybiomart==0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pybiomart==0.1) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pybiomart==0.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pybiomart==0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pybiomart==0.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pybiomart==0.1) (2025.1.31)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/dist-packages (from requests_cache->pybiomart==0.1) (25.3.0)\n",
            "Collecting cattrs>=22.2 (from requests_cache->pybiomart==0.1)\n",
            "  Downloading cattrs-24.1.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests_cache->pybiomart==0.1) (4.3.7)\n",
            "Collecting url-normalize>=1.4 (from requests_cache->pybiomart==0.1)\n",
            "  Downloading url_normalize-2.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pybiomart==0.1) (1.17.0)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-24.1.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m219.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-2.2.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: pybiomart\n",
            "  Building wheel for pybiomart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybiomart: filename=pybiomart-0.1-py3-none-any.whl size=14600 sha256=025cdb8a4b445ff707e80b896c74eacd8d78eda6a69b9f60125b6e1646dd7efd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cshg5lvp/wheels/ad/45/48/b79ec13dfdbc57735df3c6e295b70f4db768335832c07bfc57\n",
            "Successfully built pybiomart\n",
            "Installing collected packages: url-normalize, cattrs, requests_cache, pybiomart\n",
            "Successfully installed cattrs-24.1.3 pybiomart-0.1 requests_cache-1.2.1 url-normalize-2.2.0\n",
            "Collecting sklearn_som\n",
            "  Downloading sklearn_som-1.1.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sklearn_som) (2.0.2)\n",
            "Downloading sklearn_som-1.1.0-py3-none-any.whl (6.7 kB)\n",
            "Installing collected packages: sklearn_som\n",
            "Successfully installed sklearn_som-1.1.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: sklearn-som in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sklearn-som) (2.0.2)\n",
            "Collecting pyDeseq2\n",
            "  Downloading pydeseq2-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: anndata>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (0.11.4)\n",
            "Collecting formulaic>=1.0.2 (from pyDeseq2)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (1.14.1)\n",
            "Collecting formulaic-contrasts>=0.2.0 (from pyDeseq2)\n",
            "  Downloading formulaic_contrasts-1.0.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (3.10.0)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8.0->pyDeseq2) (1.11.2)\n",
            "Requirement already satisfied: h5py>=3.7 in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8.0->pyDeseq2) (3.13.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8.0->pyDeseq2) (8.4.0)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8.0->pyDeseq2) (24.2)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=1.0.2->pyDeseq2)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=1.0.2->pyDeseq2) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=1.0.2->pyDeseq2) (1.17.2)\n",
            "Collecting session-info (from formulaic-contrasts>=0.2.0->pyDeseq2)\n",
            "  Downloading session_info-1.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->pyDeseq2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->pyDeseq2) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->pyDeseq2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->pyDeseq2) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->pyDeseq2) (1.17.0)\n",
            "Collecting stdlib_list (from session-info->formulaic-contrasts>=0.2.0->pyDeseq2)\n",
            "  Downloading stdlib_list-0.11.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Downloading pydeseq2-0.5.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic_contrasts-1.0.0-py3-none-any.whl (10 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading session_info-1.0.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading stdlib_list-0.11.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m248.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stdlib_list, interface-meta, session-info, formulaic, formulaic-contrasts, pyDeseq2\n",
            "Successfully installed formulaic-1.1.1 formulaic-contrasts-1.0.0 interface-meta-1.3.0 pyDeseq2-0.5.0 session-info-1.0.1 stdlib_list-0.11.1\n",
            "Collecting Ensembl_converter\n",
            "  Downloading ensembl_converter-0.0.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from Ensembl_converter) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from Ensembl_converter) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from Ensembl_converter) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from Ensembl_converter) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->Ensembl_converter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->Ensembl_converter) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->Ensembl_converter) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->Ensembl_converter) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->Ensembl_converter) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->Ensembl_converter) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->Ensembl_converter) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->Ensembl_converter) (1.17.0)\n",
            "Downloading ensembl_converter-0.0.1-py3-none-any.whl (4.3 kB)\n",
            "Installing collected packages: Ensembl_converter\n",
            "Successfully installed Ensembl_converter-0.0.1\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import Python modules"
      ],
      "metadata": {
        "id": "cpkDoGrUsMlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook imports a number of Python modules for use in several notebooks."
      ],
      "metadata": {
        "id": "uSnhzxTaLN9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn_som.som import SOM\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import scanpy as sc\n",
        "import gseapy as gp\n",
        "from gseapy.plot import gseaplot\n",
        "from pydeseq2.dds import DeseqDataSet\n",
        "from pydeseq2.ds import DeseqStats\n",
        "from gseapy import Msigdb\n",
        "from pybiomart import Server\n",
        "#import mygene\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import TweedieRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from math import log\n",
        "import statsmodels.api as sm\n",
        "import pylab\n",
        "import operator\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from itertools import islice\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import scipy.stats as stats\n",
        "from sklearn.inspection import permutation_importance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from Ensembl_converter import EnsemblConverter\n",
        "import shap\n",
        "from sklearn.inspection import permutation_importance\n",
        "from google.colab import data_table\n",
        "#from vega_datasets import data"
      ],
      "metadata": {
        "id": "f079g46t5jTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define misc helper methods"
      ],
      "metadata": {
        "id": "xxokeQF9rjFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_maxdisplay(n=None):\n",
        "  pd.set_option('display.max_rows', n)\n",
        "  from notebook.services.config import ConfigManager\n",
        "  cm = ConfigManager().update('notebook', {'limit_output': n})"
      ],
      "metadata": {
        "id": "EpOLwn3YqdYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define data ingestion methods (For Dataset 776)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W_cXRde853Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_meta_data(dataset):\n",
        "  url = 'https://osdr.nasa.gov/geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=OSD-' + dataset + '_metadata_OSD-' + dataset + '-ISA.zip'\n",
        "  filename = dataset + '-meta.zip'\n",
        "  urlretrieve(url, filename)\n",
        "  !unzip -o {filename} > /dev/null\n",
        "  df = pd.read_csv('s_OSD-' + dataset + '.txt', sep='\\t', header=0)\n",
        "  return df"
      ],
      "metadata": {
        "id": "LwoDZ49r7i_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_rnaseq_data(data):\n",
        "  dataset = data.split('_')[0]\n",
        "  url='https://osdr.nasa.gov/geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=GLDS-' + data + '.csv'\n",
        "  df = pd.read_csv(url)\n",
        "  return df"
      ],
      "metadata": {
        "id": "eOQxRBfUs6Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_phenotype_data(dataset, data):\n",
        "  url='https://osdr.nasa.gov//geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=' + data + '.csv'\n",
        "  df = pd.read_csv(url)\n",
        "  return df"
      ],
      "metadata": {
        "id": "yCVR-HkZn08K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define data filtering methods"
      ],
      "metadata": {
        "id": "7Ga9Pbi5rr1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_cvs(df, thresh=0.5):\n",
        "\n",
        "  # calculate coefficient of variation\n",
        "  cvs=list()\n",
        "  for i in range(len(df)):\n",
        "    m=np.mean(df.iloc[i][1:])\n",
        "    sd=np.std(df.iloc[i][1:])\n",
        "    cvs.append(sd/m)\n",
        "\n",
        "  # plot hist of dist of coev of variation\n",
        "  fig, axs = plt.subplots()\n",
        "  axs.hist(cvs, bins=20)\n",
        "\n",
        "  # keep genes with cv > thresh\n",
        "  indices = list()\n",
        "  for i in range(len(cvs)):\n",
        "    if cvs[i] > thresh:\n",
        "      indices.append(i)\n",
        "  return df.iloc[indices]"
      ],
      "metadata": {
        "id": "vJaculrSRZp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_nans(df):\n",
        "  # drop NaN rows\n",
        "  df.dropna(inplace=False)\n",
        "  return df"
      ],
      "metadata": {
        "id": "0kMwy7X10hxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_lowcount(df, threshold=10):\n",
        "\n",
        "  # let's drop any low-count genes\n",
        "  print(len(df))\n",
        "  if 'transcript' in df.columns:\n",
        "    df = df[df.drop(columns=['transcript']).sum(axis=1) >= threshold]\n",
        "  elif 'Unnamed: 0' in df.columns:\n",
        "    df = df[df.drop(columns=['Unnamed: 0']).sum(axis=1) >= threshold]\n",
        "    #df.rename(columns={\"Unnamed: 0\":\"transcript\"}, inplace=True)\n",
        "  else:\n",
        "    raise Exception(\"check file format\")\n",
        "  return df"
      ],
      "metadata": {
        "id": "t1tNC979OtBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_genes(df, drop='non-coding'):\n",
        "  # let's filter protein/non-protein-coding genes\n",
        "  if drop is None:\n",
        "    return df\n",
        "  server = Server(host='http://www.ensembl.org')\n",
        "  dataset = (server.marts['ENSEMBL_MART_ENSEMBL'].datasets['mmusculus_gene_ensembl'])\n",
        "  gene_info = dataset.query(attributes=['ensembl_gene_id', 'external_gene_name', 'gene_biotype'])\n",
        "  if drop=='non-coding':\n",
        "    filter_genes=gene_info[gene_info['Gene type'] == 'protein_coding']['Gene stable ID']\n",
        "  elif drop=='coding':\n",
        "    filter_genes=gene_info[gene_info['Gene type'] != 'protein_coding']['Gene stable ID']\n",
        "  else:\n",
        "    return df\n",
        "  df=df[df['Unnamed: 0'].isin(filter_genes)]\n",
        "  return df"
      ],
      "metadata": {
        "id": "LegH26QSPhp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_data(df, dropnans=False, dropgenes='non-coding', droplowcvs=0, droplowcount=0):\n",
        "  # drop NANs\n",
        "  if dropnans:\n",
        "    df = drop_nans(df)\n",
        "  # drop non protein-coding genes\n",
        "  if not dropgenes is None:\n",
        "    df = filter_genes(df, drop=dropgenes)\n",
        "  # drop low coef of var genes\n",
        "  if droplowcvs != 0:\n",
        "    df = filter_cvs(df, droplowcvs)\n",
        "  if droplowcount != 0:\n",
        "    df = drop_lowcount(df, droplowcount)\n",
        "  return df"
      ],
      "metadata": {
        "id": "BIopMUVv2jpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exclude_samples_by_prefix(df, prefix=\"V\", colname=\"Source Name\"):\n",
        "  sample_names=list(df[colname].values)\n",
        "  exclude_names=list()\n",
        "  for sn in sample_names:\n",
        "    if sn.startswith(prefix):\n",
        "      exclude_names.append(sn)\n",
        "  return exclude_names"
      ],
      "metadata": {
        "id": "7grY5F-aEG_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersect_samples(A_list, B_list):\n",
        "  samples_A_dict = dict()\n",
        "  samples_B_list = list()\n",
        "  for i in range(len(A_list)):\n",
        "    sample = A_list[i]\n",
        "    num = \"\"\n",
        "    for c in sample:\n",
        "      if c.isdigit():\n",
        "        num += str(c)\n",
        "    if \"G\" in sample:\n",
        "      samples_A_dict[\"GC\" + num] = A_list[i]\n",
        "\n",
        "    elif \"F\" in sample:\n",
        "      samples_A_dict[\"F\" + num] = A_list[i]\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  for sample in B_list:\n",
        "    num = \"\"\n",
        "    for c in sample:\n",
        "      if c.isdigit():\n",
        "        num += str(c)\n",
        "    if \"G\" in sample:\n",
        "      samples_B_list.append(\"GC\" + num)\n",
        "    elif \"F\" in sample:\n",
        "      samples_B_list.append(\"F\" + num)\n",
        "    else:\n",
        "      continue\n",
        "  # intersect A samples with B  samples\n",
        "  samples_both=list(set(samples_A_dict.keys()) & set(samples_B_list))\n",
        "  return samples_both"
      ],
      "metadata": {
        "id": "xYp-9Ytt70y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data transformation methods"
      ],
      "metadata": {
        "id": "d4IuHC13rGZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transpose_df(df, cur_index_col, new_index_col):\n",
        "  df = df.set_index(cur_index_col).T\n",
        "  df.reset_index(level=0, inplace=True)\n",
        "  cols = [new_index_col] + list(df.columns)[1:]\n",
        "  df.columns = cols\n",
        "  return df"
      ],
      "metadata": {
        "id": "JFOBNzQ-rIW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_dims(df, current_key, new_key, n):\n",
        "  sdList = df.std(axis=1)\n",
        "  print('len of sdlist: ', str(len(sdList)))\n",
        "  sdDict = {k: v for v, k in enumerate(sdList)}\n",
        "  if n < 0:\n",
        "    sdDictSorted = sorted(sdDict.items(), key=operator.itemgetter(0), reverse=False)\n",
        "  else:\n",
        "    sdDictSorted = sorted(sdDict.items(), key=operator.itemgetter(0), reverse=True)\n",
        "  topN = sdDictSorted[0:abs(n)]\n",
        "  print('n: ', n)\n",
        "  indices = [x[1] for x in topN]\n",
        "  return df.iloc[indices]"
      ],
      "metadata": {
        "id": "6jVaYnW9rRTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pd_to_np(df):\n",
        "  X=list()\n",
        "  for col in df.columns[1:]:\n",
        "    X.append(list(df[col]))\n",
        "  return np.array(X)"
      ],
      "metadata": {
        "id": "Kip2oJPk9ArZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_symbol_from_id(gene_id_list):\n",
        "  # Create an instance of EnsemblConverter\n",
        "  converter = EnsemblConverter()\n",
        "\n",
        "  # Convert Ensembl IDs to gene symbols\n",
        "  result = converter.convert_ids(gene_id_list)\n",
        "\n",
        "  # Print the resulting DataFrame\n",
        "  gene_symbol_list = list()\n",
        "  for i in range(len(result)):\n",
        "    gene_symbol_list.append(result.iloc[i]['Symbol'])\n",
        "\n",
        "  return gene_symbol_list"
      ],
      "metadata": {
        "id": "ZqWeNhESyd5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plotting methods"
      ],
      "metadata": {
        "id": "EYvmAZ627HKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotbox_and_stats(data_, sample_key, field, treatment, space, exclude_samples=[]):\n",
        "  print('field: ', field)\n",
        "  print('excluding samples: ', exclude_samples)\n",
        "  fieldValues = set(data_[field])\n",
        "  value_dict=dict()\n",
        "  results = dict()\n",
        "\n",
        "  flight = str(field) + '_flight'\n",
        "  nonflight= str(field) + '_nonflight'\n",
        "  results[field] = dict()\n",
        "  value_dict[flight] = list()\n",
        "  value_dict[nonflight] = list()\n",
        "  for i in range(len(data_)):\n",
        "    if data_.iloc[i][sample_key] in exclude_samples:\n",
        "      continue\n",
        "    elif treatment is None:\n",
        "      if data_.iloc[i][sample_key].startswith('F'):\n",
        "        value_dict[flight].append(data_.iloc[i][field])\n",
        "      else:\n",
        "        value_dict[nonflight].append(data_.iloc[i][field])\n",
        "    else:\n",
        "      if data_.iloc[i][treatment] == space:\n",
        "        value_dict[flight].append(data_.iloc[i][field])\n",
        "      else:\n",
        "        value_dict[nonflight].append(data_.iloc[i][field])\n",
        "\n",
        "\n",
        "  if len(value_dict[flight]) != 0 and len(value_dict[nonflight]) != 0:\n",
        "    results[field]['t-test p-value'] = float('%.5f' % (stats.ttest_ind(value_dict[flight], value_dict[nonflight], equal_var=False).pvalue))\n",
        "\n",
        "  print(results)\n",
        "  print('n flight = ', len(value_dict[flight]))\n",
        "  print('n nonflight = ', len(value_dict[nonflight]))\n",
        "  fig,ax = plt.subplots()\n",
        "  ax.boxplot(value_dict.values())\n",
        "  ax.set_xticklabels(value_dict.keys())\n",
        "  plt.xticks(rotation=30, ha='right')\n",
        "\n",
        "\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "EozbsWlf7Lf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# machine learning methods\n"
      ],
      "metadata": {
        "id": "3UrOPfUfTfXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a method to run the k-means algorithm and then print which cluster each sample belongs to\n",
        "def my_kmeans(df, metadata, k):\n",
        "  # convert df to np\n",
        "  X = convert_pd_to_np(df)\n",
        "  kmeans = KMeans(n_clusters=k, random_state=42, init=\"k-means++\").fit(X)\n",
        "  # and predict each sample\n",
        "  samples = df.columns[1:]\n",
        "  for sample in samples:\n",
        "    print('sample: ', sample, ', cluster: ', kmeans.predict([list(df[sample])]), metadata[metadata['Sample Name']==sample]['Factor Value[Spaceflight]'].values[0])"
      ],
      "metadata": {
        "id": "Yt9z5IEuTh4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a method that graphs the within-cluster-sum-of-squares metric to determine the optimum value of k (the elbow method)\n",
        "def find_k_elbow(df):\n",
        "  # convert df to np\n",
        "  X = convert_pd_to_np(df)\n",
        "  wcss = []\n",
        "  for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42, n_init=i)\n",
        "    kmeans.fit(X)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "  # plot wcss\n",
        "  x=[i for i in range(1, 11)]\n",
        "  y=wcss\n",
        "\n",
        "  plt.scatter(x, y)"
      ],
      "metadata": {
        "id": "zgUckMDpTl-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_gmm(df, metadata, k):\n",
        "  # convert df to np\n",
        "  X = convert_pd_to_np(df)\n",
        "  gm = GaussianMixture(n_components=k, random_state=42).fit(X)\n",
        "  # and predict each sample\n",
        "  samples = df.columns[1:]\n",
        "  # predict probability\n",
        "  for sample in samples:\n",
        "    print('sample: ', sample, ', cluster: ', gm.predict([list(df[sample])]), metadata['255'][metadata['255']['Sample Name']==sample]['Factor Value[Spaceflight]'].values[0])\n",
        "  return gm"
      ],
      "metadata": {
        "id": "NInCRFVjoQdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_gmm_elbow(df):\n",
        "  X = convert_pd_to_np(df)\n",
        "  n_components=range(1, 11)\n",
        "  models = [GaussianMixture(n, n_init=42).fit(X) for n in n_components]\n",
        "  aics = [model.aic(X) for model in models]\n",
        "  bics = [model.bic(X) for model in models]\n",
        "  plt.figure(dpi=100)\n",
        "  plt.plot(n_components, aics, label='AIC')\n",
        "  plt.plot(n_components, bics, label='BIC')\n",
        "  plt.legend(loc='best')\n",
        "  plt.xlabel('n_components')\n",
        "  plt.ylabel('AIC or BIC')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5FVERHbDoRXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differential gene expression analysis methods\n"
      ],
      "metadata": {
        "id": "4VHHZRwjpvgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_samples_to_conditions(dfT, metadata, metadata_condition_param, condition_0, condition_1):\n",
        "  # map conditions to samples for comparison in DESeq2\n",
        "  condition_dict=dict()\n",
        "  for sample in list(dfT['sample']):\n",
        "    val=metadata[metadata['Sample Name']==sample][metadata_condition_param].values[0]\n",
        "\n",
        "    if val == condition_0:\n",
        "      condition_dict[sample] = 0\n",
        "    else:\n",
        "      condition_dict[sample] = 1\n",
        "\n",
        "\n",
        "  dfT[\"condition\"] = dfT[\"sample\"].map(condition_dict)\n",
        "  conditions=dfT[['sample', 'condition']]\n",
        "\n",
        "  return conditions"
      ],
      "metadata": {
        "id": "SAIDHbhepzIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_deseq2(df, metadata):\n",
        "  # transpose df\n",
        "  dfT = df.T\n",
        "  dfT.columns=dfT.iloc[0]\n",
        "  dfT=dfT.iloc[1:]\n",
        "  dfT.columns.name=None\n",
        "  dfT = dfT.reset_index().rename(columns={\"index\":\"sample\"})\n",
        "\n",
        "  # map conditions\n",
        "  conditions = map_samples_to_conditions(dfT, metadata, 'Factor Value[Spaceflight]', 'Ground Control', 'Space Flight')\n",
        "\n",
        "  # get count data set up for DESeq2\n",
        "  counts=dfT.drop(columns=['sample', 'condition']).reset_index(drop=True)\n",
        "  counts.applymap(np.isreal)\n",
        "  counts=counts.astype(int)\n",
        "\n",
        "  # run DESeq2\n",
        "  dds=DeseqDataSet(counts=counts, metadata=conditions, design_factors=\"condition\")\n",
        "  dds.deseq2()\n",
        "\n",
        "  return dds"
      ],
      "metadata": {
        "id": "HtFctCTHqdhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results(dds):\n",
        "  # do DGEA\n",
        "  stats_results=DeseqStats(dds, contrast = ('condition', 0, 1))\n",
        "\n",
        "  # run summary\n",
        "  stats_results.summary()\n",
        "\n",
        "  # get differentially expressed genes\n",
        "  res = stats_results.results_df\n",
        "\n",
        "  return res"
      ],
      "metadata": {
        "id": "mtkM88XOqz55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sig_genes(res, pval=0.05, l2fc=0):\n",
        "  sigs = res[(res.padj < pval) & (abs(res.log2FoldChange) > l2fc)]\n",
        "  return sigs"
      ],
      "metadata": {
        "id": "LTT1I17Ardvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dge_ranked_genes(res):\n",
        "  # rank genes from most to least significantly differentially expressed\n",
        "  ranking = res[['stat']].dropna().sort_values('stat', ascending=False)\n",
        "  ranking_index=list(ranking.index)\n",
        "  ranking_index_upper=[x.upper() for x in ranking_index]\n",
        "  ranking.index=ranking_index_upper\n",
        "\n",
        "  return ranking"
      ],
      "metadata": {
        "id": "vtkWQuXmrvuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_by_dgea(data, metadata,  pval, l2fc):\n",
        "  # run DESeq2\n",
        "  dds = run_deseq2(data, metadata)\n",
        "\n",
        "  # get results\n",
        "  res = get_results(dds)\n",
        "\n",
        "  # get sig genes\n",
        "  sig_genes_df = get_sig_genes(res, pval=pval, l2fc=l2fc)\n",
        "\n",
        "  # get top sig genes\n",
        "  top_genes = list(sig_genes_df.sort_values('padj').index)\n",
        "\n",
        "  # filter data by topn_genes\n",
        "  return data[data['Unnamed: 0'].isin(top_genes)]\n"
      ],
      "metadata": {
        "id": "OjjASIsmgRx3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}